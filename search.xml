<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>创建神经网络并进行训练和查询</title>
      <link href="/2019/08/03/%E5%88%9B%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B9%B6%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E5%92%8C%E6%9F%A5%E8%AF%A2/"/>
      <url>/2019/08/03/%E5%88%9B%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B9%B6%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E5%92%8C%E6%9F%A5%E8%AF%A2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>摘要：通过对神经网络编程这本书的内容，模仿其中的代码，对初次学习神经网络进行熟悉，并逐步完成神经网络的搭建，完成对手写数字的识别。</p><a id="more"></a><h2 id="神经网络的三大步骤"><a href="#神经网络的三大步骤" class="headerlink" title="神经网络的三大步骤"></a>神经网络的三大步骤</h2><ol><li><p>初始化函数–设定输入节点、隐藏节点和输出节点的数量。</p></li><li><p>训练–学习给定的训练集样本后，优化权重。</p></li><li><p>查询–给定输入，从输出的节点给出答案。</p></li></ol><h2 id="初始化网络–输入"><a href="#初始化网络–输入" class="headerlink" title="初始化网络–输入"></a>初始化网络–输入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self , inputnodes , hiddennodes , outputnodes , learningrate)</span>:</span>   </span><br><span class="line">        <span class="comment">#set number of nodes in each input, hidden, output layer</span></span><br><span class="line">    </span><br><span class="line">        self.inodes = inputnodes</span><br><span class="line">        self.hnodes = hiddennodes</span><br><span class="line">        self.onodes = outputnodes</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#链接权重矩阵</span></span><br><span class="line">        <span class="comment">#link weight matrices, wih and who 注释：此处wih的意思是 w:权重  i:input  h:hidden ,后面的who同理</span></span><br><span class="line">        <span class="comment">#weights inside the arrays are w_i_j,where link is from node i to node j in the next layter</span></span><br><span class="line">        <span class="comment">#w11 w21</span></span><br><span class="line">        <span class="comment">#w12 w22 etc</span></span><br><span class="line">        self.wih = (numpy.random.rand(self.hnodes, self.inodes) - <span class="number">0.5</span>)</span><br><span class="line">        self.who = (numpy.random.rand(self.onodes, self.hnodes) - <span class="number">0.5</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment">#learning rate</span></span><br><span class="line">        self.lr = learningrate</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#导入scipy.special 才可以用</span></span><br><span class="line">        <span class="comment">#activation function is the sigmoid function</span></span><br><span class="line">        <span class="comment">#使用lambda来创建函数， 函数接受了X，返回了scipy.special.expit(x)，这就是S函数，使用lambda创建的匿名函数</span></span><br><span class="line">        self.activation_function = <span class="keyword">lambda</span> x: scipy.special.expit(x)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>其中，需要注意的地方有：</p><ul><li>函数名 __init__是前后两条“_” ,如果只有一条下划线的话会报错TypeError : object() takes no parameters</li></ul><p>参考链接：<a href="https://blog.csdn.net/qq_26489165/article/details/80595864" target="_blank" rel="noopener">https://blog.csdn.net/qq_26489165/article/details/80595864</a></p><ul><li>链接权重矩阵：此处wih的意思是 w:权重  i:input  h:hidden ,后面的whoy也是同理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.wih = (numpy.random.rand(self.hnodes, self.inodes) - <span class="number">0.5</span>)</span><br><span class="line">self.who = (numpy.random.rand(self.onodes, self.hnodes) - <span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><ul><li>使用lambda来创建函数， 函数接受了X，返回了scipy.special.expit(x)，这就是S函数，使用lambda创建的匿名函数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.activation_function = <span class="keyword">lambda</span> x: scipy.special.expit(x)</span><br></pre></td></tr></table></figure><h2 id="初始化网络–查询"><a href="#初始化网络–查询" class="headerlink" title="初始化网络–查询"></a>初始化网络–查询</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#convert inouts list to 2d array</span></span><br><span class="line">        inputs = numpy.array(inputs_list,ndmin= <span class="number">2</span> ) .T</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#calculate signals into hidden layer</span></span><br><span class="line">        hidden_inputs = numpy.dot(self.wih , inputs)</span><br><span class="line">        <span class="comment">#calculate the signals emerging from hidden layer</span></span><br><span class="line">        hidden_outputs = self.activation_function(hidden_inputs)</span><br><span class="line">        <span class="comment">#calculate signals into final output layer</span></span><br><span class="line">        final_inputs = numpy.dot(self.who , hidden_outputs)</span><br><span class="line">        <span class="comment">#calculate the signals emerging from final output layer</span></span><br><span class="line">        final_outputs = self.activation_function(final_inputs)</span><br><span class="line">        <span class="keyword">return</span> final_outputs</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h2 id="初始化网络–训练"><a href="#初始化网络–训练" class="headerlink" title="初始化网络–训练"></a>初始化网络–训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#train the neural network</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, input_list, targets_list)</span>:</span></span><br><span class="line">    <span class="comment">#可以发现下面的代码和query中的几乎完全一样。因为所使用的从输入层前馈信号到最终输出层完全一样。而多处理的targets 是用来训练样本的。</span></span><br><span class="line">    <span class="comment">#cober inputs list to 2d array</span></span><br><span class="line">    inputs = numpy.array(input_list,ndmin=<span class="number">2</span>).T</span><br><span class="line">    targets = numpy.array(targets_list,ndmin=<span class="number">2</span>).T</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#calculate signals into hidden layer</span></span><br><span class="line">    hidden_inputs = numpy.dot(self.wih , inputs)</span><br><span class="line">    <span class="comment">#calculate the signals emerging from hidden layer</span></span><br><span class="line">    hidden_outputs = self.activation_function(hidden_inputs)</span><br><span class="line">     <span class="comment">#calculate signals into final output layer</span></span><br><span class="line">    final_inputs = numpy.dot(self.who , hidden_outputs)</span><br><span class="line">    <span class="comment">#calculate the signals emerging from final output layer</span></span><br><span class="line">    final_outputs = self.activation_function(final_inputs)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#error is the (target -actual),即为反向传播的误差</span></span><br><span class="line">    output_errors = targets - final_outputs</span><br><span class="line">    <span class="comment">#hidden layer error is the output_errors , split by weights,recombined at hodden nodes</span></span><br><span class="line">    hidden_errors = numpy.dot(self.who.T , output_errors)</span><br><span class="line">    <span class="comment">#update the weights for the links between the hidden and output layers</span></span><br><span class="line">    <span class="comment">#其中，学习率是self.lr  利用numpy.dot进行矩阵的乘法</span></span><br><span class="line">    self.who += self.lr * numpy.dot((output_errors * final_outputs * (<span class="number">1.0</span> - final_outputs)), numpy.transpose(hidden_outputs))</span><br><span class="line">    <span class="comment">#update the weights for the links between the intput and hidden layers</span></span><br><span class="line">    self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (<span class="number">1.0</span> - hidden_outputs)), numpy.transpose(inputs))</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>其中，需要注意的是：</p><ol><li>可以发现下面的代码和query中的几乎完全一样。因为所使用的从输入层前馈信号到最终输出层完全一样。而多处理的targets 是用来训练样本的。</li><li>而error中error is the (target -actual),即为反向传播的误差</li><li>学习率是self.lr  利用numpy.dot进行矩阵的乘法</li></ol><h2 id="创建神经网络对象"><a href="#创建神经网络对象" class="headerlink" title="创建神经网络对象"></a>创建神经网络对象</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#number of input, hidden and output nodes</span></span><br><span class="line">input_nodes = <span class="number">784</span></span><br><span class="line">hidden_nodes = <span class="number">100</span></span><br><span class="line">output_nodes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#learn rate is 0.3 （学习率）</span></span><br><span class="line">learning_rate = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#create instance of neural network</span></span><br><span class="line">n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)</span><br></pre></td></tr></table></figure><p>为什么选择784个输入节点呢？请记住这是28*28的结果，即是组成手写数字图像的像素个数。</p><p>选择100个隐藏节点并没有固定规定，书中认为神经网络可以发现在输入中的特征或模式，这些模式或者特征可以使用比输入本身更简短的表达，因此没有和选择比784大的数字。选择比输入节点小的数量来强制网络尝试总结输入的主要特点。但选择太少的隐藏节点就限制了网络的能力。给定10个输出层的节点对应的是10个标签。</p><p>强调一点：对于一个问题，选择多少个隐藏层节点并不存在一份最佳方法。最好的办法就是进行实验，直到找到适合你解决问题的一个数字。</p><h2 id="测试网络"><a href="#测试网络" class="headerlink" title="测试网络"></a>测试网络</h2><ul><li>打开文件</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#load the mnist training data CSV file into a list</span></span><br><span class="line">training_data_file = open(<span class="string">"TestandTrain/mnist_train_100.csv"</span>,<span class="string">'r'</span>)</span><br><span class="line">training_data_list = training_data_file.readlines()</span><br><span class="line">training_data_file.close()</span><br></pre></td></tr></table></figure><p>将文件放在同目录下即可直接调用</p><ul><li>训练网络</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train the neural network</span></span><br><span class="line"><span class="comment"># go through all records in the training data set </span></span><br><span class="line"><span class="keyword">for</span> record <span class="keyword">in</span> training_data_list:</span><br><span class="line">    <span class="comment"># split the record by the ',' commas</span></span><br><span class="line">    all_values = record.split(<span class="string">','</span>)</span><br><span class="line">    <span class="comment"># scale and shift the inputs</span></span><br><span class="line">    inputs = (numpy.asfarray(all_values[<span class="number">1</span>:]) / <span class="number">255.0</span> * <span class="number">0.99</span>) + <span class="number">0.01</span></span><br><span class="line">    targets = numpy.zeros(output_nodes) + <span class="number">0.01</span></span><br><span class="line">    <span class="comment"># all_values[0] is the target label for this record</span></span><br><span class="line">    targets[int(all_values[<span class="number">0</span>])] = <span class="number">0.99</span></span><br><span class="line">    n.train(inputs, targets)</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h2 id="查询网络"><a href="#查询网络" class="headerlink" title="查询网络"></a>查询网络</h2><ul><li>打开文件</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#load the mnist test data CSV file into a list</span></span><br><span class="line">test_data_file = open(<span class="string">"TestandTrain/mnist_test_10.csv"</span>,<span class="string">'r'</span>)</span><br><span class="line">test_data_list = test_data_file.readlines()</span><br><span class="line">test_data_file.close()</span><br></pre></td></tr></table></figure><ul><li>打印标签</li></ul><p>并进行matplotlib进行图形化显示并查看测试概率</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#get the first test record</span></span><br><span class="line">all_values = test_data_list[<span class="number">2</span>].split(<span class="string">','</span>)</span><br><span class="line"><span class="comment">#print the lable</span></span><br><span class="line"><span class="comment">#打印标签</span></span><br><span class="line">print(<span class="string">'label:'</span>,all_values[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">image_array = numpy.asfarray(all_values[<span class="number">1</span>:]).reshape((<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">matplotlib.pyplot.imshow(image_array,cmap=<span class="string">'Greys'</span>,interpolation=<span class="string">'None'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n.query((numpy.asfarray(all_values[<span class="number">1</span>:])/ <span class="number">255.0</span> * <span class="number">0.99</span>) + <span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="comment">#scipy.special for the sigmoid function expit()</span></span><br><span class="line"><span class="keyword">import</span> scipy.special</span><br><span class="line"><span class="comment">#添加绘图库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#neural network classdefinition</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">neuralNetwork</span>:</span></span><br><span class="line">    <span class="comment">#初始化网络</span></span><br><span class="line">    <span class="comment">#initialise the neural netwoak</span></span><br><span class="line">    <span class="comment">#注意！-----&gt;此处init前后均是双下划线，否则报错</span></span><br><span class="line">    <span class="comment">#TypeError: object() takes no parameters</span></span><br><span class="line">    <span class="comment">#参考链接：https://blog.csdn.net/qq_26489165/article/details/80595864</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self , inputnodes , hiddennodes , outputnodes , learningrate)</span>:</span>   </span><br><span class="line">        <span class="comment">#set number of nodes in each input, hidden, output layer</span></span><br><span class="line">    </span><br><span class="line">        self.inodes = inputnodes</span><br><span class="line">        self.hnodes = hiddennodes</span><br><span class="line">        self.onodes = outputnodes</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#链接权重矩阵</span></span><br><span class="line">        <span class="comment">#link weight matrices, wih and who 注释：此处wih的意思是 w:权重  i:input  h:hidden ,后面的who同理</span></span><br><span class="line">        <span class="comment">#weights inside the arrays are w_i_j,where link is from node i to node j in the next layter</span></span><br><span class="line">        <span class="comment">#w11 w21</span></span><br><span class="line">        <span class="comment">#w12 w22 etc</span></span><br><span class="line">        self.wih = (numpy.random.rand(self.hnodes, self.inodes) - <span class="number">0.5</span>)</span><br><span class="line">        self.who = (numpy.random.rand(self.onodes, self.hnodes) - <span class="number">0.5</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment">#learning rate</span></span><br><span class="line">        self.lr = learningrate</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#导入scipy.special 才可以用</span></span><br><span class="line">        <span class="comment">#activation function is the sigmoid function</span></span><br><span class="line">        <span class="comment">#使用lambda来创建函数， 函数接受了X，返回了scipy.special.expit(x)，这就是S函数，使用lambda创建的匿名函数</span></span><br><span class="line">        self.activation_function = <span class="keyword">lambda</span> x: scipy.special.expit(x)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#train the neural network</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, input_list, targets_list)</span>:</span></span><br><span class="line">        <span class="comment">#可以发现下面的代码和query中的几乎完全一样。因为所使用的从输入层前馈信号到最终输出层完全一样。而多处理的targets 是用来训练样本的。</span></span><br><span class="line">        <span class="comment">#cober inputs list to 2d array</span></span><br><span class="line">        inputs = numpy.array(input_list,ndmin=<span class="number">2</span>).T</span><br><span class="line">        targets = numpy.array(targets_list,ndmin=<span class="number">2</span>).T</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#calculate signals into hidden layer</span></span><br><span class="line">        hidden_inputs = numpy.dot(self.wih , inputs)</span><br><span class="line">        <span class="comment">#calculate the signals emerging from hidden layer</span></span><br><span class="line">        hidden_outputs = self.activation_function(hidden_inputs)</span><br><span class="line">         <span class="comment">#calculate signals into final output layer</span></span><br><span class="line">        final_inputs = numpy.dot(self.who , hidden_outputs)</span><br><span class="line">        <span class="comment">#calculate the signals emerging from final output layer</span></span><br><span class="line">        final_outputs = self.activation_function(final_inputs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#error is the (target -actual),即为反向传播的误差</span></span><br><span class="line">        output_errors = targets - final_outputs</span><br><span class="line">        <span class="comment">#hidden layer error is the output_errors , split by weights,recombined at hodden nodes</span></span><br><span class="line">        hidden_errors = numpy.dot(self.who.T , output_errors)</span><br><span class="line">        <span class="comment">#update the weights for the links between the hidden and output layers</span></span><br><span class="line">        <span class="comment">#其中，学习率是self.lr  利用numpy.dot进行矩阵的乘法</span></span><br><span class="line">        self.who += self.lr * numpy.dot((output_errors * final_outputs * (<span class="number">1.0</span> - final_outputs)), numpy.transpose(hidden_outputs))</span><br><span class="line">        <span class="comment">#update the weights for the links between the intput and hidden layers</span></span><br><span class="line">        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (<span class="number">1.0</span> - hidden_outputs)), numpy.transpose(inputs))</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#query the neural network</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">query</span><span class="params">(self, inputs_list)</span>:</span></span><br><span class="line">        <span class="comment">#convert inouts list to 2d array</span></span><br><span class="line">        inputs = numpy.array(inputs_list,ndmin= <span class="number">2</span> ) .T</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#calculate signals into hidden layer</span></span><br><span class="line">        hidden_inputs = numpy.dot(self.wih , inputs)</span><br><span class="line">        <span class="comment">#calculate the signals emerging from hidden layer</span></span><br><span class="line">        hidden_outputs = self.activation_function(hidden_inputs)</span><br><span class="line">        <span class="comment">#calculate signals into final output layer</span></span><br><span class="line">        final_inputs = numpy.dot(self.who , hidden_outputs)</span><br><span class="line">        <span class="comment">#calculate the signals emerging from final output layer</span></span><br><span class="line">        final_outputs = self.activation_function(final_inputs)</span><br><span class="line">        <span class="keyword">return</span> final_outputs</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#number of input, hidden and output nodes</span></span><br><span class="line">input_nodes = <span class="number">784</span></span><br><span class="line">hidden_nodes = <span class="number">100</span></span><br><span class="line">output_nodes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#learn rate is 0.3</span></span><br><span class="line">learning_rate = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#create instance of neural network</span></span><br><span class="line">n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)</span><br><span class="line"><span class="comment">#load the mnist training data CSV file into a list</span></span><br><span class="line">training_data_file = open(<span class="string">"TestandTrain/mnist_train_100.csv"</span>,<span class="string">'r'</span>)</span><br><span class="line">training_data_list = training_data_file.readlines()</span><br><span class="line">training_data_file.close()</span><br><span class="line"><span class="comment"># train the neural network</span></span><br><span class="line"><span class="comment"># go through all records in the training data set </span></span><br><span class="line"><span class="keyword">for</span> record <span class="keyword">in</span> training_data_list:</span><br><span class="line">    <span class="comment"># split the record by the ',' commas</span></span><br><span class="line">    all_values = record.split(<span class="string">','</span>)</span><br><span class="line">    <span class="comment"># scale and shift the inputs</span></span><br><span class="line">    inputs = (numpy.asfarray(all_values[<span class="number">1</span>:]) / <span class="number">255.0</span> * <span class="number">0.99</span>) + <span class="number">0.01</span></span><br><span class="line">    targets = numpy.zeros(output_nodes) + <span class="number">0.01</span></span><br><span class="line">    <span class="comment"># all_values[0] is the target label for this record</span></span><br><span class="line">    targets[int(all_values[<span class="number">0</span>])] = <span class="number">0.99</span></span><br><span class="line">    n.train(inputs, targets)</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment">#load the mnist test data CSV file into a list</span></span><br><span class="line">test_data_file = open(<span class="string">"TestandTrain/mnist_test_10.csv"</span>,<span class="string">'r'</span>)</span><br><span class="line">test_data_list = test_data_file.readlines()</span><br><span class="line">test_data_file.close()</span><br><span class="line"><span class="comment">#get the first test record</span></span><br><span class="line">all_values = test_data_list[<span class="number">2</span>].split(<span class="string">','</span>)</span><br><span class="line"><span class="comment">#print the lable</span></span><br><span class="line"><span class="comment">#打印标签</span></span><br><span class="line">print(<span class="string">'label:'</span>,all_values[<span class="number">0</span>])</span><br><span class="line"><span class="comment">#get the first test record</span></span><br><span class="line">all_values = test_data_list[<span class="number">2</span>].split(<span class="string">','</span>)</span><br><span class="line"><span class="comment">#print the lable</span></span><br><span class="line"><span class="comment">#打印标签</span></span><br><span class="line">print(<span class="string">'label:'</span>,all_values[<span class="number">0</span>])</span><br><span class="line">image_array = numpy.asfarray(all_values[<span class="number">1</span>:]).reshape((<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">matplotlib.pyplot.imshow(image_array,cmap=<span class="string">'Greys'</span>,interpolation=<span class="string">'None'</span>)</span><br><span class="line">n.query((numpy.asfarray(all_values[<span class="number">1</span>:])/ <span class="number">255.0</span> * <span class="number">0.99</span>) + <span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><p>记得给代码加上头文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="comment">#scipy.special for the sigmoid function expit()</span></span><br><span class="line"><span class="keyword">import</span> scipy.special</span><br><span class="line"><span class="comment">#添加绘图库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Typora极简教程</title>
      <link href="/2019/07/27/Typora%E6%9E%81%E7%AE%80%E6%95%99%E7%A8%8B/"/>
      <url>/2019/07/27/Typora%E6%9E%81%E7%AE%80%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>摘要： <strong>Markdown</strong> 是一种<strong>轻量级</strong>标记语言，创始人是<strong>约翰·格鲁伯</strong>（John Gruber）。它允许人们 “使用易读易写的纯文本格式编写文档，然后转换成有效的 HTML 文档。”</p><a id="more"></a><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>Typora官方下载：<a href="https://www.typora.io/#download" target="_blank" rel="noopener">https://www.typora.io/#download</a></p><hr><h2 id="常用快捷键"><a href="#常用快捷键" class="headerlink" title="常用快捷键"></a>常用快捷键</h2><ul><li>加粗： <code>Ctrl/Cmd + B</code></li><li>标题： <code>Ctrl/Cmd + H</code></li><li>插入链接： <code>Ctrl/Cmd + K</code></li><li>插入代码： <code>Ctrl/Cmd + Shift + C</code></li><li>行内代码： <code>Ctrl/Cmd + Shift + K</code></li><li>插入图片： <code>Ctrl/Cmd + Shift + I</code></li><li>无序列表： <code>Ctrl/Cmd + Shift + L</code></li><li>撤销： <code>Ctrl/Cmd + Z</code></li><li>一级标题：快捷键为<code>Ctrl + 1</code>，以此类推</li></ul><hr><h2 id="引用文字"><a href="#引用文字" class="headerlink" title="引用文字"></a>引用文字</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="quote">&gt; + 空格 + 引用文字</span></span><br><span class="line"><span class="quote">&gt; 引用内容1</span></span><br><span class="line"><span class="quote">&gt; 引用内容2</span></span><br><span class="line">&gt;&gt; 引用内容3</span><br></pre></td></tr></table></figure><blockquote><p>引用内容1<br>引用内容2</p><blockquote><p>引用内容3</p></blockquote></blockquote><hr><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><p>输入  <em>列表内容 将创建一个无序列表，该</em>符号可以替换为+或-。</p><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">* </span>无序列表1</span><br><span class="line"><span class="bullet">+ </span>无序列表2</span><br><span class="line"><span class="bullet">- </span>无序列表3</span><br></pre></td></tr></table></figure><ul><li>无序列表1</li></ul><ul><li>无序列表2</li></ul><ul><li>无序列表3</li></ul><h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1. </span>有序列表1</span><br><span class="line"><span class="bullet">2. </span>有序列表2</span><br><span class="line"><span class="bullet">3. </span>有序列表3</span><br></pre></td></tr></table></figure><ol><li>有序列表1</li><li>有序列表2</li><li>有序列表3</li></ol><h3 id="多行无序列表"><a href="#多行无序列表" class="headerlink" title="多行无序列表"></a>多行无序列表</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">* </span>多行无序列表1</span><br><span class="line">TAB * 多行无序列表2</span><br><span class="line">TAB TAB * 多行无序列表3</span><br></pre></td></tr></table></figure><ul><li>多行无序列表1<ul><li>多行无序列表2<ul><li>多行无序列表3</li></ul></li></ul></li></ul><h3 id="任务列表"><a href="#任务列表" class="headerlink" title="任务列表"></a>任务列表</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-[ ] 不抽烟</span><br><span class="line">-[x] 不喝酒</span><br><span class="line">-[ ] 不烫头</span><br></pre></td></tr></table></figure><p>-[ ] 不抽烟<br>-[x] 不喝酒<br>-[ ] 不烫头</p><h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">|姓名|性别|年龄|手机号|</span><br><span class="line">|:---|:--:|:--:|---:|</span><br><span class="line">|居左|居中|居中|居右|</span><br><span class="line">|张三|男|21|18975346876|</span><br><span class="line">|李四|女|23|17789548964|</span><br><span class="line">|王五|男|25|15876513546|</span><br></pre></td></tr></table></figure><table><thead><tr><th align="left">姓名</th><th align="center">性别</th><th align="center">年龄</th><th align="right">手机号</th></tr></thead><tbody><tr><td align="left">居左</td><td align="center">居中</td><td align="center">居中</td><td align="right">居右</td></tr><tr><td align="left">张三</td><td align="center">男</td><td align="center">21</td><td align="right">18975346876</td></tr><tr><td align="left">李四</td><td align="center">女</td><td align="center">23</td><td align="right">17789548964</td></tr><tr><td align="left">王五</td><td align="center">男</td><td align="center">25</td><td align="right">15876513546</td></tr></tbody></table><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><h4 id="本地图片"><a href="#本地图片" class="headerlink" title="本地图片"></a>本地图片</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[图片上传失败...(image-61fd19-1520850984854)]</span><br></pre></td></tr></table></figure><h4 id="网络图片"><a href="#网络图片" class="headerlink" title="网络图片"></a>网络图片</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![<span class="string">pikachu.jpg</span>](<span class="link">https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1564157419510&amp;di=e96d9359d9cba4b936ed55eb804c54bb&amp;imgtype=0&amp;src=http%3A%2F%2Fdata.whicdn.com%2Fimages%2F3045613%2Flarge.jpg</span>)</span><br></pre></td></tr></table></figure><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1564157419510&di=e96d9359d9cba4b936ed55eb804c54bb&imgtype=0&src=http%3A%2F%2Fdata.whicdn.com%2Fimages%2F3045613%2Flarge.jpg" alt="pikachu.jpg"></p><h3 id="超链接"><a href="#超链接" class="headerlink" title="超链接"></a>超链接</h3><h4 id="行内式链接"><a href="#行内式链接" class="headerlink" title="行内式链接"></a>行内式链接</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">我的博客</span>][<span class="symbol">https://hongcyu.github.io</span>]</span><br></pre></td></tr></table></figure><p>[我的博客][<a href="https://hongcyu.github.io]" target="_blank" rel="noopener">https://hongcyu.github.io]</a></p><h4 id="参考式链接"><a href="#参考式链接" class="headerlink" title="参考式链接"></a>参考式链接</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">CSDN</span>][<span class="symbol">CSDN网址</span>]</span><br><span class="line">[<span class="symbol">CSDN网址</span>]:<span class="link">https://www.csdn.net/</span></span><br></pre></td></tr></table></figure><p><a href="https://www.csdn.net/" target="_blank" rel="noopener">CSDN</a></p><h4 id="自动链接"><a href="#自动链接" class="headerlink" title="自动链接"></a>自动链接</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;https://www.github.com&gt;</span><br><span class="line">或</span><br><span class="line">https://www.github.com</span><br></pre></td></tr></table></figure><p><a href="https://www.github.com" target="_blank" rel="noopener">https://www.github.com</a></p><p><a href="https://www.github.com" target="_blank" rel="noopener">https://www.github.com</a></p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="斜体"><a href="#斜体" class="headerlink" title="斜体"></a>斜体</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="emphasis">*斜体*</span></span><br><span class="line"><span class="emphasis">_斜体_</span></span><br></pre></td></tr></table></figure><p><em>斜体</em><br><em>斜体</em></p><h3 id="加粗"><a href="#加粗" class="headerlink" title="加粗"></a>加粗</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="strong">**加粗**</span></span><br><span class="line"><span class="strong">__加粗__</span></span><br></pre></td></tr></table></figure><p><strong>加粗</strong><br><strong>加粗</strong></p><h3 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;u&gt;下划线&lt;/u&gt;</span><br></pre></td></tr></table></figure><p><u>下划线</u></p><h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~~删除线~~</span><br></pre></td></tr></table></figure><p><del>删除线</del></p><h3 id="分隔线"><a href="#分隔线" class="headerlink" title="分隔线"></a>分隔线</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">***</span><br><span class="line">---</span><br><span class="line">___</span><br></pre></td></tr></table></figure><hr><hr><hr><h3 id="注脚"><a href="#注脚" class="headerlink" title="注脚"></a>注脚</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Typora[^1]</span><br><span class="line">[^1]A markdown editor</span><br></pre></td></tr></table></figure><p>Typora[^1]<br>[^1]A markdown editor</p><h3 id="符号的输入"><a href="#符号的输入" class="headerlink" title="符号的输入"></a>符号的输入</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">\\   反斜线</span><br><span class="line">\`   反引号</span><br><span class="line">\*   星号</span><br><span class="line">\_   底线</span><br><span class="line">\&#123; \&#125;  花括号</span><br><span class="line">\[ \]  方括号</span><br><span class="line">\( \)  括弧</span><br><span class="line">\#   井字号</span><br><span class="line">\+   加号</span><br><span class="line">\-   减号</span><br><span class="line">\.   英文句点</span><br><span class="line">\!   惊叹号</span><br></pre></td></tr></table></figure><p>\   反斜线<br>`   反引号<br>*   星号<br>_   底线<br>{ }  花括号<br>[ ]  方括号<br>( )  括弧<br>#   井字号<br>+   加号<br>-   减号<br>.   英文句点<br>!   惊叹号</p><h3 id="特殊字符"><a href="#特殊字符" class="headerlink" title="特殊字符"></a>特殊字符</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&amp;copy;      版权      </span><br><span class="line">&amp;reg;       注册商标</span><br><span class="line">&amp;trade;     商标</span><br><span class="line">&amp;nbsp;      空格</span><br><span class="line">&amp;amp;       和号</span><br><span class="line">&amp;quot;      引号</span><br><span class="line">&amp;apos;      撇号</span><br><span class="line">&amp;lt;        小于号</span><br><span class="line">&amp;gt;        大于号</span><br><span class="line">&amp;ne;        不等号</span><br><span class="line">&amp;le;        小于等于</span><br><span class="line">&amp;ge;        大于等于</span><br><span class="line">&amp;cent;      分</span><br><span class="line">&amp;pound;     磅</span><br><span class="line">&amp;euro;      欧元</span><br><span class="line">&amp;yen;       元</span><br><span class="line">&amp;sect;      节</span><br><span class="line">&amp;times;     乘号</span><br><span class="line">&amp;divide;    除号</span><br><span class="line">&amp;plusmn;    正负号</span><br></pre></td></tr></table></figure><p>&copy;      版权<br>&reg;       注册商标<br>&trade;     商标<br>&nbsp;      空格<br>&amp;       和号<br>&quot;      引号<br>&apos;      撇号<br>&lt;        小于号<br>&gt;        大于号<br>&ne;        不等号<br>&le;        小于等于<br>&ge;        大于等于<br>&cent;      分<br>&pound;     磅<br>&euro;      欧元<br>&yen;       元<br>&sect;      节<br>&times;     乘号<br>&divide;    除号<br>&plusmn;    正负号</p><p>附件：[HTML特殊字符编码对照表][<a href="https://www.jb51.net/onlineread/htmlchar.htm]" target="_blank" rel="noopener">https://www.jb51.net/onlineread/htmlchar.htm]</a></p><h2 id="插入音乐和视频"><a href="#插入音乐和视频" class="headerlink" title="插入音乐和视频"></a>插入音乐和视频</h2><h3 id="音乐"><a href="#音乐" class="headerlink" title="音乐"></a>音乐</h3><p>1）直接用 HTML 的标签，写法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;audio src=&quot;https://什么什么什么.mp3&quot; style=&quot;max-height :100%; max-width: 100%; display: block; margin-left: auto; margin-right: auto;&quot; controls=&quot;controls&quot; loop=&quot;loop&quot; preload=&quot;meta&quot;&gt;Your browser does not support the audio tag.&lt;/audio&gt;</span><br></pre></td></tr></table></figure><p>2）用插件，有显示歌词功能，也美观。首先在<strong>站点</strong>文件夹根目录安装插件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-tag-aplayer --save</span><br></pre></td></tr></table></figure><p>然后文章中的写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% aplayer &quot;歌曲名&quot; &quot;歌手名&quot; &quot;https://什么什么什么.mp3&quot; &quot;https://封面图.jpg&quot; &quot;lrc:https://歌词.lrc&quot; %&#125;</span><br></pre></td></tr></table></figure><p>另外可以支持歌单：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;% aplayerlist %&#125;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;autoplay&quot;: false,</span><br><span class="line">    &quot;showlrc&quot;: 3,</span><br><span class="line">    &quot;mutex&quot;: true,</span><br><span class="line">    &quot;music&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;title&quot;: &quot;歌曲名&quot;,</span><br><span class="line">            &quot;author&quot;: &quot;歌手名&quot;,</span><br><span class="line">            &quot;url&quot;: &quot;https://什么什么什么.mp3&quot;,</span><br><span class="line">            &quot;pic&quot;: &quot;https://封面图.jpg&quot;,</span><br><span class="line">            &quot;lrc&quot;: &quot;https://歌词.lrc&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;title&quot;: &quot;歌曲名&quot;,</span><br><span class="line">            &quot;author&quot;: &quot;歌手名&quot;,</span><br><span class="line">            &quot;url&quot;: &quot;https://什么什么什么.mp3&quot;,</span><br><span class="line">            &quot;pic&quot;: &quot;https://封面图.jpg&quot;,</span><br><span class="line">            &quot;lrc&quot;: &quot;https://歌词.lrc&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">&#123;% endaplayerlist %&#125;</span><br></pre></td></tr></table></figure><p>里面的详细参数见 <a href="https://github.com/MoePlayer/hexo-tag-aplayer" target="_blank" rel="noopener">README</a> 和这插件的「母亲」Aplayer 的<a href="https://aplayer.js.org/" target="_blank" rel="noopener">官方文档</a>。关于 <a href="https://baike.baidu.com/item/lrc/46935" target="_blank" rel="noopener">LRC</a>歌词，可以用<a href="https://www.zhihu.com/question/27638171" target="_blank" rel="noopener">工具</a>下载网易云音乐的歌词，另发现暂时不支持<code>offset</code>参数。当然，如果那歌词很操蛋，有错误（比如字母大小写和标点符号乱加）或者时间完全对不上，然后你也和我一样是个完美主义者，那接下来就是令人窒息的操作了，一句一句自己查看修改……</p><p>什么，你想把网易云的几百首歌手动同步到博客？慢慢慢，有一种<a href="https://github.com/MoePlayer/hexo-tag-aplayer#meingjs-support-new-in-30" target="_blank" rel="noopener">非常简单的方法</a>，此这种方法也支持单曲，将参数里的<code>playlist</code>更改为<code>song</code>即可，非常建议食用！更多功能请仔细阅读 README。</p><h3 id="视频"><a href="#视频" class="headerlink" title="视频"></a>视频</h3><p>1）直接用 HTML 的标签，写法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;video poster=&quot;https://封面图.jpg&quot; src=&quot;https://什么什么什么.mp4&quot; style=&quot;max-height :100%; max-width: 100%; display: block; margin-left: auto; margin-right: auto;&quot; controls=&quot;controls&quot; loop=&quot;loop&quot; preload=&quot;meta&quot;&gt;Your browser does not support the video tag.&lt;/video&gt;</span><br></pre></td></tr></table></figure><p>2）用插件，可支持弹幕，首先在站点文件夹根目录安装插件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-tag-dplayer --save</span><br></pre></td></tr></table></figure><p>然后文章中的写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% dplayer &quot;url=https://什么什么什么.mp4&quot; &quot;https://封面图.jpg&quot; &quot;api=https://api.prprpr.me/dplayer/&quot; &quot;id=&quot; &quot;loop=false&quot; %&#125;</span><br></pre></td></tr></table></figure><p>要使用弹幕，必须有<code>api</code>和<code>id</code>两项，并且若使用的是官方的 api 地址（即上面的），id 的值不能与<a href="https://api.prprpr.me/dplayer/list" target="_blank" rel="noopener">这个列表</a>的值一样。id 的值自己随便取，唯一要求就是前面这点。如果唯一要求难倒了你，可以使用<a href="http://tool.oschina.net/encrypt?type=2" target="_blank" rel="noopener">这个工具</a>将一段与众不同的文字生成一段看起来毫无意义的哈希值，这样看起来是不是好多了。</p><p>当然，这个插件的功能还有很多，可以去 <a href="https://github.com/MoePlayer/hexo-tag-dplayer" target="_blank" rel="noopener">README</a> 和这插件的「母亲」Dplayer 的<a href="https://dplayer.js.org/" target="_blank" rel="noopener">官方文档</a>看看。</p>]]></content>
      
      
      <categories>
          
          <category> 书写格式 </category>
          
          <category> Typora </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Typora </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo的简单命令</title>
      <link href="/2019/07/25/hexo%E7%9A%84%E7%AE%80%E5%8D%95%E5%91%BD%E4%BB%A4/"/>
      <url>/2019/07/25/hexo%E7%9A%84%E7%AE%80%E5%8D%95%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>介绍了Hexo的一些简单命令。</p><a id="more"></a><h2 id="hexo-s"><a href="#hexo-s" class="headerlink" title="hexo s"></a>hexo s</h2><p>启动本地服务器，用于预览主题。默认地址： <a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a><br>hexo s 是 hexo server 的缩写，命令效果一致；<br>预览的同时可以修改文章内容或主题代码，保存后刷新页面即可；<br>对 Hexo 根目录 _config.yml 的修改，需要重启本地服务器后才能预览效果。</p><hr><h2 id="hexo-new-“学习笔记”"><a href="#hexo-new-“学习笔记”" class="headerlink" title="hexo new “学习笔记”"></a>hexo new “学习笔记”</h2><p>新建一篇标题为 学习笔记 的文章，因为标题里有空格，所以加上了引号。<br>文章标题可以在对应 md 文件里改，新建时标题可以写的简单些。</p><hr><h2 id="hexo-d"><a href="#hexo-d" class="headerlink" title="hexo d"></a>hexo d</h2><p>自动生成网站静态文件，并部署到设定的仓库。<br>hexo d 是 hexo deploy 的缩写，命令效果一致。</p><hr><h2 id="hexo-clean"><a href="#hexo-clean" class="headerlink" title="hexo clean"></a>hexo clean</h2><p>清除缓存文件 db.json 和已生成的静态文件 public 。<br>网站显示异常时可以执行这条命令试试。</p><hr><h2 id="hexo-g"><a href="#hexo-g" class="headerlink" title="hexo g"></a>hexo g</h2><p>生成网站静态文件到默认设置的 public 文件夹。<br>便于查看网站生成的静态文件或者手动部署网站；<br>如果使用自动部署，不需要先执行该命令；<br>hexo g 是 hexo generate 的缩写，命令效果一致。</p><hr><h2 id="hexo-new-page-aboutme"><a href="#hexo-new-page-aboutme" class="headerlink" title="hexo new page aboutme"></a>hexo new page aboutme</h2><p>新建一个标题为 aboutme 的页面，默认链接地址为 主页地址/aboutme/<br>标题可以为中文，但一般习惯用英文；<br>页面标题和文章一样可以随意修改；<br>页面不会出现在首页文章列表和归档中，也不支持设置分类和标签。</p><hr><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.bilibili.com/video/av44544186" target="_blank" rel="noopener">https://www.bilibili.com/video/av44544186</a><br><a href="https://blog.csdn.net/dxxzst/article/details/76135935" target="_blank" rel="noopener">https://blog.csdn.net/dxxzst/article/details/76135935</a></p>]]></content>
      
      
      <categories>
          
          <category> 命令格式 </category>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
