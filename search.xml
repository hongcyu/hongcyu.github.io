<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[创建神经网络并进行训练和查询]]></title>
    <url>%2F2019%2F08%2F03%2F%E5%88%9B%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B9%B6%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E5%92%8C%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[摘要：通过对神经网络编程这本书的内容，模仿其中的代码，对初次学习神经网络进行熟悉，并逐步完成神经网络的搭建，完成对手写数字的识别。 神经网络的三大步骤 初始化函数–设定输入节点、隐藏节点和输出节点的数量。 训练–学习给定的训练集样本后，优化权重。 查询–给定输入，从输出的节点给出答案。 初始化网络–输入1234567891011121314151617181920212223242526def __init__(self , inputnodes , hiddennodes , outputnodes , learningrate): #set number of nodes in each input, hidden, output layer self.inodes = inputnodes self.hnodes = hiddennodes self.onodes = outputnodes #链接权重矩阵 #link weight matrices, wih and who 注释：此处wih的意思是 w:权重 i:input h:hidden ,后面的who同理 #weights inside the arrays are w_i_j,where link is from node i to node j in the next layter #w11 w21 #w12 w22 etc self.wih = (numpy.random.rand(self.hnodes, self.inodes) - 0.5) self.who = (numpy.random.rand(self.onodes, self.hnodes) - 0.5) #learning rate self.lr = learningrate #导入scipy.special 才可以用 #activation function is the sigmoid function #使用lambda来创建函数， 函数接受了X，返回了scipy.special.expit(x)，这就是S函数，使用lambda创建的匿名函数 self.activation_function = lambda x: scipy.special.expit(x) pass 其中，需要注意的地方有： 函数名 __init__是前后两条“_” ,如果只有一条下划线的话会报错： TypeError : object() takes no parameters 参考链接：https://blog.csdn.net/qq_26489165/article/details/80595864 链接权重矩阵：此处wih的意思是 w:权重 i:input h:hidden ,后面的whoy也是同理 12self.wih = (numpy.random.rand(self.hnodes, self.inodes) - 0.5)self.who = (numpy.random.rand(self.onodes, self.hnodes) - 0.5) 使用lambda来创建函数， 函数接受了X，返回了scipy.special.expit(x)，这就是S函数，使用lambda创建的匿名函数 1self.activation_function = lambda x: scipy.special.expit(x) 初始化网络–查询12345678910111213#convert inouts list to 2d array inputs = numpy.array(inputs_list,ndmin= 2 ) .T #calculate signals into hidden layer hidden_inputs = numpy.dot(self.wih , inputs) #calculate the signals emerging from hidden layer hidden_outputs = self.activation_function(hidden_inputs) #calculate signals into final output layer final_inputs = numpy.dot(self.who , hidden_outputs) #calculate the signals emerging from final output layer final_outputs = self.activation_function(final_inputs) return final_outputs pass 初始化网络–训练1234567891011121314151617181920212223242526#train the neural networkdef train(self, input_list, targets_list): #可以发现下面的代码和query中的几乎完全一样。因为所使用的从输入层前馈信号到最终输出层完全一样。而多处理的targets 是用来训练样本的。 #cober inputs list to 2d array inputs = numpy.array(input_list,ndmin=2).T targets = numpy.array(targets_list,ndmin=2).T #calculate signals into hidden layer hidden_inputs = numpy.dot(self.wih , inputs) #calculate the signals emerging from hidden layer hidden_outputs = self.activation_function(hidden_inputs) #calculate signals into final output layer final_inputs = numpy.dot(self.who , hidden_outputs) #calculate the signals emerging from final output layer final_outputs = self.activation_function(final_inputs) #error is the (target -actual),即为反向传播的误差 output_errors = targets - final_outputs #hidden layer error is the output_errors , split by weights,recombined at hodden nodes hidden_errors = numpy.dot(self.who.T , output_errors) #update the weights for the links between the hidden and output layers #其中，学习率是self.lr 利用numpy.dot进行矩阵的乘法 self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs)) #update the weights for the links between the intput and hidden layers self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs)) pass 其中，需要注意的是： 可以发现下面的代码和query中的几乎完全一样。因为所使用的从输入层前馈信号到最终输出层完全一样。而多处理的targets 是用来训练样本的。 而error中error is the (target -actual),即为反向传播的误差 学习率是self.lr 利用numpy.dot进行矩阵的乘法 创建神经网络对象12345678910#number of input, hidden and output nodesinput_nodes = 784hidden_nodes = 100output_nodes = 10#learn rate is 0.3 （学习率）learning_rate = 0.3#create instance of neural networkn = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate) 为什么选择784个输入节点呢？请记住这是28*28的结果，即是组成手写数字图像的像素个数。 选择100个隐藏节点并没有固定规定，书中认为神经网络可以发现在输入中的特征或模式，这些模式或者特征可以使用比输入本身更简短的表达，因此没有和选择比784大的数字。选择比输入节点小的数量来强制网络尝试总结输入的主要特点。但选择太少的隐藏节点就限制了网络的能力。给定10个输出层的节点对应的是10个标签。 强调一点：对于一个问题，选择多少个隐藏层节点并不存在一份最佳方法。最好的办法就是进行实验，直到找到适合你解决问题的一个数字。 测试网络 打开文件 1234#load the mnist training data CSV file into a listtraining_data_file = open("TestandTrain/mnist_train_100.csv",'r')training_data_list = training_data_file.readlines()training_data_file.close() 将文件放在同目录下即可直接调用 训练网络 123456789101112# train the neural network# go through all records in the training data set for record in training_data_list: # split the record by the ',' commas all_values = record.split(',') # scale and shift the inputs inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01 targets = numpy.zeros(output_nodes) + 0.01 # all_values[0] is the target label for this record targets[int(all_values[0])] = 0.99 n.train(inputs, targets) pass 查询网络 打开文件 1234#load the mnist test data CSV file into a listtest_data_file = open("TestandTrain/mnist_test_10.csv",'r')test_data_list = test_data_file.readlines()test_data_file.close() 打印标签，并进行matplotlib进行图形化显示并查看测试概率 1234567891011#get the first test recordall_values = test_data_list[2].split(',')#print the lable#打印标签print('label:',all_values[0])image_array = numpy.asfarray(all_values[1:]).reshape((28,28))matplotlib.pyplot.imshow(image_array,cmap='Greys',interpolation='None')n.query((numpy.asfarray(all_values[1:])/ 255.0 * 0.99) + 0.01) 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127import numpy#scipy.special for the sigmoid function expit()import scipy.special#添加绘图库import matplotlib.pyplot%matplotlib inline#neural network classdefinitionclass neuralNetwork: #初始化网络 #initialise the neural netwoak #注意！-----&gt;此处init前后均是双下划线，否则报错 #TypeError: object() takes no parameters #参考链接：https://blog.csdn.net/qq_26489165/article/details/80595864 def __init__(self , inputnodes , hiddennodes , outputnodes , learningrate): #set number of nodes in each input, hidden, output layer self.inodes = inputnodes self.hnodes = hiddennodes self.onodes = outputnodes #链接权重矩阵 #link weight matrices, wih and who 注释：此处wih的意思是 w:权重 i:input h:hidden ,后面的who同理 #weights inside the arrays are w_i_j,where link is from node i to node j in the next layter #w11 w21 #w12 w22 etc self.wih = (numpy.random.rand(self.hnodes, self.inodes) - 0.5) self.who = (numpy.random.rand(self.onodes, self.hnodes) - 0.5) #learning rate self.lr = learningrate #导入scipy.special 才可以用 #activation function is the sigmoid function #使用lambda来创建函数， 函数接受了X，返回了scipy.special.expit(x)，这就是S函数，使用lambda创建的匿名函数 self.activation_function = lambda x: scipy.special.expit(x) pass #train the neural network def train(self, input_list, targets_list): #可以发现下面的代码和query中的几乎完全一样。因为所使用的从输入层前馈信号到最终输出层完全一样。而多处理的targets 是用来训练样本的。 #cober inputs list to 2d array inputs = numpy.array(input_list,ndmin=2).T targets = numpy.array(targets_list,ndmin=2).T #calculate signals into hidden layer hidden_inputs = numpy.dot(self.wih , inputs) #calculate the signals emerging from hidden layer hidden_outputs = self.activation_function(hidden_inputs) #calculate signals into final output layer final_inputs = numpy.dot(self.who , hidden_outputs) #calculate the signals emerging from final output layer final_outputs = self.activation_function(final_inputs) #error is the (target -actual),即为反向传播的误差 output_errors = targets - final_outputs #hidden layer error is the output_errors , split by weights,recombined at hodden nodes hidden_errors = numpy.dot(self.who.T , output_errors) #update the weights for the links between the hidden and output layers #其中，学习率是self.lr 利用numpy.dot进行矩阵的乘法 self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs)) #update the weights for the links between the intput and hidden layers self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs)) pass #query the neural network def query(self, inputs_list): #convert inouts list to 2d array inputs = numpy.array(inputs_list,ndmin= 2 ) .T #calculate signals into hidden layer hidden_inputs = numpy.dot(self.wih , inputs) #calculate the signals emerging from hidden layer hidden_outputs = self.activation_function(hidden_inputs) #calculate signals into final output layer final_inputs = numpy.dot(self.who , hidden_outputs) #calculate the signals emerging from final output layer final_outputs = self.activation_function(final_inputs) return final_outputs pass #number of input, hidden and output nodesinput_nodes = 784hidden_nodes = 100output_nodes = 10#learn rate is 0.3learning_rate = 0.3#create instance of neural networkn = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)#load the mnist training data CSV file into a listtraining_data_file = open("TestandTrain/mnist_train_100.csv",'r')training_data_list = training_data_file.readlines()training_data_file.close()# train the neural network# go through all records in the training data set for record in training_data_list: # split the record by the ',' commas all_values = record.split(',') # scale and shift the inputs inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01 targets = numpy.zeros(output_nodes) + 0.01 # all_values[0] is the target label for this record targets[int(all_values[0])] = 0.99 n.train(inputs, targets) pass #load the mnist test data CSV file into a listtest_data_file = open("TestandTrain/mnist_test_10.csv",'r')test_data_list = test_data_file.readlines()test_data_file.close()#get the first test recordall_values = test_data_list[2].split(',')#print the lable#打印标签print('label:',all_values[0])#get the first test recordall_values = test_data_list[2].split(',')#print the lable#打印标签print('label:',all_values[0])image_array = numpy.asfarray(all_values[1:]).reshape((28,28))matplotlib.pyplot.imshow(image_array,cmap='Greys',interpolation='None')n.query((numpy.asfarray(all_values[1:])/ 255.0 * 0.99) + 0.01) 记得给代码加上头文件 123456import numpy#scipy.special for the sigmoid function expit()import scipy.special#添加绘图库import matplotlib.pyplot%matplotlib inline]]></content>
      <categories>
        <category>python</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Typora极简教程]]></title>
    <url>%2F2019%2F07%2F27%2FTypora%E6%9E%81%E7%AE%80%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[摘要： Markdown 是一种轻量级标记语言，创始人是约翰·格鲁伯（John Gruber）。它允许人们 “使用易读易写的纯文本格式编写文档，然后转换成有效的 HTML 文档。” 下载Typora官方下载：https://www.typora.io/#download 常用快捷键 加粗： Ctrl/Cmd + B 标题： Ctrl/Cmd + H 插入链接： Ctrl/Cmd + K 插入代码： Ctrl/Cmd + Shift + C 行内代码： Ctrl/Cmd + Shift + K 插入图片： Ctrl/Cmd + Shift + I 无序列表： Ctrl/Cmd + Shift + L 撤销： Ctrl/Cmd + Z 一级标题：快捷键为Ctrl + 1，以此类推 引用文字1234&gt; + 空格 + 引用文字&gt; 引用内容1&gt; 引用内容2&gt;&gt; 引用内容3 引用内容1引用内容2 引用内容3 列表输入 列表内容 将创建一个无序列表，该符号可以替换为+或-。 无序列表123* 无序列表1+ 无序列表2- 无序列表3 无序列表1 无序列表2 无序列表3 有序列表1231. 有序列表12. 有序列表23. 有序列表3 有序列表1 有序列表2 有序列表3 多行无序列表123* 多行无序列表1TAB * 多行无序列表2TAB TAB * 多行无序列表3 多行无序列表1 多行无序列表2 多行无序列表3 任务列表123-[ ] 不抽烟-[x] 不喝酒-[ ] 不烫头 -[ ] 不抽烟-[x] 不喝酒-[ ] 不烫头 表格123456|姓名|性别|年龄|手机号||:---|:--:|:--:|---:||居左|居中|居中|居右||张三|男|21|18975346876||李四|女|23|17789548964||王五|男|25|15876513546| 姓名 性别 年龄 手机号 居左 居中 居中 居右 张三 男 21 18975346876 李四 女 23 17789548964 王五 男 25 15876513546 链接图片本地图片1[图片上传失败...(image-61fd19-1520850984854)] 网络图片1![pikachu.jpg](https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1564157419510&amp;di=e96d9359d9cba4b936ed55eb804c54bb&amp;imgtype=0&amp;src=http%3A%2F%2Fdata.whicdn.com%2Fimages%2F3045613%2Flarge.jpg) 超链接行内式链接1[我的博客][https://hongcyu.github.io] [我的博客][https://hongcyu.github.io] 参考式链接12[CSDN][CSDN网址][CSDN网址]:https://www.csdn.net/ CSDN 自动链接123&lt;https://www.github.com&gt;或https://www.github.com https://www.github.com https://www.github.com 其他斜体12*斜体*_斜体_ 斜体斜体 加粗12**加粗**__加粗__ 加粗加粗 下划线1&lt;u&gt;下划线&lt;/u&gt; 下划线 删除线1~~删除线~~ 删除线 分隔线123***---___ 注脚12Typora[^1][^1]A markdown editor Typora[^1][^1]A markdown editor 符号的输入123456789101112\\ 反斜线\` 反引号\* 星号\_ 底线\&#123; \&#125; 花括号\[ \] 方括号\( \) 括弧\# 井字号\+ 加号\- 减号\. 英文句点\! 惊叹号 \ 反斜线` 反引号* 星号_ 底线{ } 花括号[ ] 方括号( ) 括弧# 井字号+ 加号- 减号. 英文句点! 惊叹号 特殊字符1234567891011121314151617181920&amp;copy; 版权 &amp;reg; 注册商标&amp;trade; 商标&amp;nbsp; 空格&amp;amp; 和号&amp;quot; 引号&amp;apos; 撇号&amp;lt; 小于号&amp;gt; 大于号&amp;ne; 不等号&amp;le; 小于等于&amp;ge; 大于等于&amp;cent; 分&amp;pound; 磅&amp;euro; 欧元&amp;yen; 元&amp;sect; 节&amp;times; 乘号&amp;divide; 除号&amp;plusmn; 正负号 &copy; 版权&reg; 注册商标&trade; 商标&nbsp; 空格&amp; 和号&quot; 引号&apos; 撇号&lt; 小于号&gt; 大于号&ne; 不等号&le; 小于等于&ge; 大于等于&cent; 分&pound; 磅&euro; 欧元&yen; 元&sect; 节&times; 乘号&divide; 除号&plusmn; 正负号 附件：[HTML特殊字符编码对照表][https://www.jb51.net/onlineread/htmlchar.htm] 插入音乐和视频音乐1）直接用 HTML 的标签，写法如下： 1&lt;audio src=&quot;https://什么什么什么.mp3&quot; style=&quot;max-height :100%; max-width: 100%; display: block; margin-left: auto; margin-right: auto;&quot; controls=&quot;controls&quot; loop=&quot;loop&quot; preload=&quot;meta&quot;&gt;Your browser does not support the audio tag.&lt;/audio&gt; 2）用插件，有显示歌词功能，也美观。首先在站点文件夹根目录安装插件： 1npm install hexo-tag-aplayer --save 然后文章中的写法： 1&#123;% aplayer &quot;歌曲名&quot; &quot;歌手名&quot; &quot;https://什么什么什么.mp3&quot; &quot;https://封面图.jpg&quot; &quot;lrc:https://歌词.lrc&quot; %&#125; 另外可以支持歌单： 1234567891011121314151617181920212223&#123;% aplayerlist %&#125;&#123; &quot;autoplay&quot;: false, &quot;showlrc&quot;: 3, &quot;mutex&quot;: true, &quot;music&quot;: [ &#123; &quot;title&quot;: &quot;歌曲名&quot;, &quot;author&quot;: &quot;歌手名&quot;, &quot;url&quot;: &quot;https://什么什么什么.mp3&quot;, &quot;pic&quot;: &quot;https://封面图.jpg&quot;, &quot;lrc&quot;: &quot;https://歌词.lrc&quot; &#125;, &#123; &quot;title&quot;: &quot;歌曲名&quot;, &quot;author&quot;: &quot;歌手名&quot;, &quot;url&quot;: &quot;https://什么什么什么.mp3&quot;, &quot;pic&quot;: &quot;https://封面图.jpg&quot;, &quot;lrc&quot;: &quot;https://歌词.lrc&quot; &#125; ]&#125;&#123;% endaplayerlist %&#125; 里面的详细参数见 README 和这插件的「母亲」Aplayer 的官方文档。关于 LRC歌词，可以用工具下载网易云音乐的歌词，另发现暂时不支持offset参数。当然，如果那歌词很操蛋，有错误（比如字母大小写和标点符号乱加）或者时间完全对不上，然后你也和我一样是个完美主义者，那接下来就是令人窒息的操作了，一句一句自己查看修改…… 什么，你想把网易云的几百首歌手动同步到博客？慢慢慢，有一种非常简单的方法，此这种方法也支持单曲，将参数里的playlist更改为song即可，非常建议食用！更多功能请仔细阅读 README。 视频1）直接用 HTML 的标签，写法如下： 1&lt;video poster=&quot;https://封面图.jpg&quot; src=&quot;https://什么什么什么.mp4&quot; style=&quot;max-height :100%; max-width: 100%; display: block; margin-left: auto; margin-right: auto;&quot; controls=&quot;controls&quot; loop=&quot;loop&quot; preload=&quot;meta&quot;&gt;Your browser does not support the video tag.&lt;/video&gt; 2）用插件，可支持弹幕，首先在站点文件夹根目录安装插件： 1npm install hexo-tag-dplayer --save 然后文章中的写法： 1&#123;% dplayer &quot;url=https://什么什么什么.mp4&quot; &quot;https://封面图.jpg&quot; &quot;api=https://api.prprpr.me/dplayer/&quot; &quot;id=&quot; &quot;loop=false&quot; %&#125; 要使用弹幕，必须有api和id两项，并且若使用的是官方的 api 地址（即上面的），id 的值不能与这个列表的值一样。id 的值自己随便取，唯一要求就是前面这点。如果唯一要求难倒了你，可以使用这个工具将一段与众不同的文字生成一段看起来毫无意义的哈希值，这样看起来是不是好多了。 当然，这个插件的功能还有很多，可以去 README 和这插件的「母亲」Dplayer 的官方文档看看。]]></content>
      <categories>
        <category>书写格式</category>
        <category>Typora</category>
      </categories>
      <tags>
        <tag>Typora</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo的简单命令]]></title>
    <url>%2F2019%2F07%2F25%2Fhexo%E7%9A%84%E7%AE%80%E5%8D%95%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[介绍了Hexo的一些简单命令。 hexo s启动本地服务器，用于预览主题。默认地址： http://localhost:4000/hexo s 是 hexo server 的缩写，命令效果一致；预览的同时可以修改文章内容或主题代码，保存后刷新页面即可；对 Hexo 根目录 _config.yml 的修改，需要重启本地服务器后才能预览效果。 hexo new “学习笔记”新建一篇标题为 学习笔记 的文章，因为标题里有空格，所以加上了引号。文章标题可以在对应 md 文件里改，新建时标题可以写的简单些。 hexo d自动生成网站静态文件，并部署到设定的仓库。hexo d 是 hexo deploy 的缩写，命令效果一致。 hexo clean清除缓存文件 db.json 和已生成的静态文件 public 。网站显示异常时可以执行这条命令试试。 hexo g生成网站静态文件到默认设置的 public 文件夹。便于查看网站生成的静态文件或者手动部署网站；如果使用自动部署，不需要先执行该命令；hexo g 是 hexo generate 的缩写，命令效果一致。 hexo new page aboutme新建一个标题为 aboutme 的页面，默认链接地址为 主页地址/aboutme/标题可以为中文，但一般习惯用英文；页面标题和文章一样可以随意修改；页面不会出现在首页文章列表和归档中，也不支持设置分类和标签。 参考文献https://www.bilibili.com/video/av44544186https://blog.csdn.net/dxxzst/article/details/76135935]]></content>
      <categories>
        <category>命令格式</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
